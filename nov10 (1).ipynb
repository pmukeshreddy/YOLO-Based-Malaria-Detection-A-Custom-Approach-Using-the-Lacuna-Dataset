{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9502706,"sourceType":"datasetVersion","datasetId":5783394}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\nfrom PIL import Image\nimport torch\nfrom torchvision import transforms\n\nclass_map = {\"Trophozoite\": 0, \"NEG\": 1, \"WBC\": 2}\nclass_names = {v: k for k, v in class_map.items()}\n\nclass MalariaDataset(Dataset):\n    def __init__(self, csv_file, image_dir, s=7, transform=None):\n        self.annotations = pd.read_csv(csv_file)\n        self.image_dir = image_dir\n        self.s = s\n        self.c = len(class_map)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.annotations[\"Image_ID\"].unique())\n\n    def __getitem__(self, idx):\n        image_id = self.annotations[\"Image_ID\"].unique()[idx]\n        image_path = os.path.join(self.image_dir, image_id)\n        image = Image.open(image_path).convert(\"RGB\")\n        \n        # Resize the image to (448, 448)\n        image = image.resize((448, 448))\n        \n        if self.transform:\n            image = self.transform(image)\n\n        target = torch.zeros((self.s, self.s, self.c + 5))\n\n        image_annotations = self.annotations[self.annotations[\"Image_ID\"] == image_id]\n        for _, row in image_annotations.iterrows():\n            x_min = row[\"xmin\"]\n            x_max = row[\"xmax\"]\n            y_min = row[\"ymin\"]\n            y_max = row[\"ymax\"]\n\n            x_centers = (x_min + x_max) / 2 / 448\n            y_centers = (y_min + y_max) / 2 / 448\n            box_width = (x_max - x_min) / 448\n            box_height = (y_max - y_min) / 448\n\n            i = min(int(y_centers * self.s), self.s - 1)\n            j = min(int(x_centers * self.s), self.s - 1)\n\n            if target[i, j, self.c] == 0:\n                target[i, j, self.c] = 1\n                target[i, j, self.c+1:self.c+5] = torch.tensor(\n                    [x_centers, y_centers, box_width, box_height]\n                )\n                class_label = class_map[row[\"class\"]]\n                target[i, j, class_label] = 1\n        assert not torch.isnan(target).any(), \"Target contains NaN!\"\n        assert not (target < 0).any(), \"Target contains negative values!\"\n        assert target.shape == (self.s, self.s, self.c + 5), \"Incorrect target shape!\"\n\n        return image, target\n\n\ndef collate_fn(batch):\n    images, targets = zip(*batch)\n    images = torch.stack(images)\n    targets = torch.stack([t for t in targets])\n    return images, targets\n\n\n# Define transformations with normalization\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Instantiate the dataset and dataloader\ndataset_train = MalariaDataset(\n    \"/kaggle/input/lacuna-malaria-detection-dataset/Train.csv\",\n    \"/kaggle/input/lacuna-malaria-detection-dataset/images\",\n    transform=transform\n)\n\ntrain_dataloader = DataLoader(dataset_train, batch_size=8, collate_fn=collate_fn)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:37.859467Z","iopub.execute_input":"2024-11-20T05:56:37.860187Z","iopub.status.idle":"2024-11-20T05:56:37.893435Z","shell.execute_reply.started":"2024-11-20T05:56:37.860153Z","shell.execute_reply":"2024-11-20T05:56:37.892849Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def visualize_samples(dataloader, num_samples=5, skip_samples=20):\n    fig, axes = plt.subplots(1, num_samples, figsize=(15, 6))\n    \n    for idx, (image, target) in enumerate(dataloader):\n        if idx < skip_samples:\n            continue\n        if idx >= skip_samples + num_samples:\n            break\n            \n        # Handle batch dimension\n        if image.dim() == 4:\n            img_np = image[0].permute(1, 2, 0).numpy()\n        else:\n            img_np = image.permute(1, 2, 0).numpy()\n            \n        ax = axes[idx - skip_samples]\n        ax.imshow(img_np)\n        \n        # Handle batch dimension in target\n        if isinstance(target, list):\n            target = target[0]\n            \n        boxes = target[\"boxes\"]\n        labels = target[\"lables\"]  # Fixed ty\n\n        if boxes.dim() == 1:\n            boxes = boxes.unsqueeze(0)\n        if labels.dim() == 0:\n            labels = labels.unsqueeze(0)\n            \n        for box, label in zip(boxes, labels):\n            x_min, y_min, x_max, y_max = box.numpy()\n            \n            # Skip invalid boxes\n            if (x_min == 0 and x_max == 0 and y_min == 0 and y_max == 0):\n                continue\n                \n            width = x_max - x_min\n            height = y_max - y_min\n            #label_value = label.item()\n            #print(\"Label value:\", label_value)\n            label_value = label.item()\n           # if label_value in class_names:\n            #    print(\"Class name:\", class_names[label_value])\n            #else:\n             #   print(\"Label value not found in class_names:\", label_value)\n            \n            rect = patches.Rectangle(\n                (x_min, y_min), width, height,\n                edgecolor=\"red\",\n                facecolor=\"none\"\n            )\n            ax.add_patch(rect)\n\n          #  print(label)\n            \n            # Add label\n          #  print(label.item())\n          #  print(class_names.get(label.item()))\n         #   print(class_names.get(label.item(), \"Unknown\"),)\n            label_value = label.item()\n            class_name = class_names.get(label_value)\n\n            ax.text(\n                x_min, y_min,\n                class_name,\n                color=\"red\",\n                fontsize=12,\n                bbox=dict(facecolor=\"white\", alpha=0.7)\n            )\n        ax.set_title(f\"Sample {idx + 1}\")\n        ax.axis(\"off\")\n        \n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:38.439598Z","iopub.execute_input":"2024-11-20T05:56:38.439924Z","iopub.status.idle":"2024-11-20T05:56:38.449297Z","shell.execute_reply.started":"2024-11-20T05:56:38.439896Z","shell.execute_reply":"2024-11-20T05:56:38.448355Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"yolov1","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass YOLOv1(nn.Module):\n    def __init__(self, s=7, b=2, c=3):\n        super(YOLOv1, self).__init__()\n        self.s = s\n        self.b = b\n        self.c = c\n\n        # Convolutional layers\n        self.conv_layers = nn.Sequential(\n            # Layer 1\n\n            \n            \n            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n            nn.BatchNorm2d(64),\n            nn.LeakyReLU(0.1),\n            nn.Dropout(0.5),\n            nn.MaxPool2d(2, 2),\n            \n            # Layer 2\n            nn.Conv2d(64, 192, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(192),\n            nn.Dropout(0.5),\n            nn.LeakyReLU(0.1),\n            nn.MaxPool2d(2, 2),\n            \n            # Layers 3-5\n            nn.Conv2d(192, 128, kernel_size=1, stride=1, padding=0),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.1),\n            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(256),\n            nn.LeakyReLU(0.1),\n            nn.Conv2d(256, 512, kernel_size=1, stride=1, padding=0),\n            nn.BatchNorm2d(512),\n            nn.LeakyReLU(0.1),\n            nn.Dropout(0.5),\n            nn.MaxPool2d(2, 2),\n\n            # Layers 6-10\n            nn.Conv2d(512, 256, kernel_size=1, stride=1, padding=0),\n            nn.BatchNorm2d(256),\n            nn.LeakyReLU(0.1),\n            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(512),\n            nn.LeakyReLU(0.1),\n            nn.Conv2d(512, 256, kernel_size=1, stride=1, padding=0),\n            nn.BatchNorm2d(256),\n            nn.LeakyReLU(0.1),\n            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(512),\n            nn.LeakyReLU(0.1),\n            nn.Conv2d(512, 512, kernel_size=1, stride=1, padding=0),\n            nn.BatchNorm2d(512),\n            nn.LeakyReLU(0.1),\n            nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(1024),\n            nn.LeakyReLU(0.1),\n            nn.Dropout(0.5),\n            nn.MaxPool2d(2, 2),\n            \n            # Layers 11-15\n            nn.Conv2d(1024, 512, kernel_size=1, stride=1, padding=0),\n            nn.Dropout(0.5),\n            nn.BatchNorm2d(512),\n            nn.LeakyReLU(0.1),\n            nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(1024),\n            nn.LeakyReLU(0.1),\n            nn.Conv2d(1024, 512, kernel_size=1, stride=1, padding=0),\n            nn.BatchNorm2d(512),\n            nn.LeakyReLU(0.1),\n            nn.Dropout(0.5),\n            nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(1024),\n            nn.LeakyReLU(0.1),\n            nn.Conv2d(1024, 1024, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(1024),\n            nn.LeakyReLU(0.1),\n            nn.Conv2d(1024, 1024, kernel_size=3, stride=2, padding=1),\n            nn.BatchNorm2d(1024),\n            nn.Dropout(0.5),\n            nn.LeakyReLU(0.1),\n            \n            # Final convolutional layers before FC layers\n            nn.Conv2d(1024, 1024, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(1024),\n            nn.LeakyReLU(0.1),\n            nn.Conv2d(1024, 1024, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(1024),\n            nn.Dropout(0.5),\n            nn.LeakyReLU(0.1),\n        )\n        \n        # Fully connected layers\n        self.fc_layers = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(1024 * 7 * 7, 4096),\n            nn.LeakyReLU(0.1),\n            nn.Dropout(0.5),\n            nn.Linear(4096, s * s * (b * 5 + c)),\n        )\n        \n        # Initialize weights\n        self._initialize_weights()\n    \n    def forward(self, x):\n        # Add activation checking after each major block\n        for i, layer in enumerate(self.conv_layers):\n            x = layer(x)\n            if torch.isnan(x).any():\n                print(f\"NaN detected in conv layer {i}\")\n                print(f\"Layer type: {type(layer)}\")\n                return None\n            \n            # Print statistics periodically\n       #     if i % 10 == 0:\n        #        print(f\"Layer {i} stats:\")\n         #       print(f\"Mean: {x.mean().item():.4f}\")\n          #      print(f\"Std: {x.std().item():.4f}\")\n           #     print(f\"Min: {x.min().item():.4f}\")\n            #    print(f\"Max: {x.max().item():.4f}\")\n        \n        # Check before FC layers\n      #  print(\"Before FC layers:\")\n       # print(f\"Shape: {x.shape}\")\n        #print(f\"Range: [{x.min().item():.4f}, {x.max().item():.4f}]\")\n\n      #  print(\"Shape before FC layers:\", x.shape)\n\n        for i, layer in enumerate(self.fc_layers):\n            x = layer(x)\n           # print(x.shape)\n            if torch.isnan(x).any():\n                print(f\"NaN detected in fc layer {i}\")\n                print(f\"Layer type: {type(layer)}\")\n                return None\n        \n        return x.view(-1, self.s, self.s, self.b * 5 + self.c)\n    \n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n            # Use more conservative initialization for first layer\n                if m is self.conv_layers[0]:\n                    nn.init.normal_(m.weight, mean=0, std=0.01)\n                else:\n                    nn.init.kaiming_normal_(m.weight, a=0.1, mode='fan_out', nonlinearity='leaky_relu')\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                nn.init.normal_(m.weight, mean=0, std=0.01)\n                nn.init.constant_(m.bias, 0)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:39.405638Z","iopub.execute_input":"2024-11-20T05:56:39.405929Z","iopub.status.idle":"2024-11-20T05:56:39.423817Z","shell.execute_reply.started":"2024-11-20T05:56:39.405904Z","shell.execute_reply":"2024-11-20T05:56:39.422804Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"model = YOLOv1()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:39.806831Z","iopub.execute_input":"2024-11-20T05:56:39.807130Z","iopub.status.idle":"2024-11-20T05:56:44.076810Z","shell.execute_reply.started":"2024-11-20T05:56:39.807103Z","shell.execute_reply":"2024-11-20T05:56:44.076058Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:44.078076Z","iopub.execute_input":"2024-11-20T05:56:44.078361Z","iopub.status.idle":"2024-11-20T05:56:44.572254Z","shell.execute_reply.started":"2024-11-20T05:56:44.078328Z","shell.execute_reply":"2024-11-20T05:56:44.571390Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"YOLOv1(\n  (conv_layers): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): LeakyReLU(negative_slope=0.1)\n    (3): Dropout(p=0.5, inplace=False)\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (5): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (6): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (7): Dropout(p=0.5, inplace=False)\n    (8): LeakyReLU(negative_slope=0.1)\n    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (10): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (12): LeakyReLU(negative_slope=0.1)\n    (13): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (15): LeakyReLU(negative_slope=0.1)\n    (16): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n    (17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (18): LeakyReLU(negative_slope=0.1)\n    (19): Dropout(p=0.5, inplace=False)\n    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (21): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n    (22): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (23): LeakyReLU(negative_slope=0.1)\n    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (26): LeakyReLU(negative_slope=0.1)\n    (27): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n    (28): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (29): LeakyReLU(negative_slope=0.1)\n    (30): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (32): LeakyReLU(negative_slope=0.1)\n    (33): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (35): LeakyReLU(negative_slope=0.1)\n    (36): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (37): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (38): LeakyReLU(negative_slope=0.1)\n    (39): Dropout(p=0.5, inplace=False)\n    (40): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (41): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n    (42): Dropout(p=0.5, inplace=False)\n    (43): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (44): LeakyReLU(negative_slope=0.1)\n    (45): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (46): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (47): LeakyReLU(negative_slope=0.1)\n    (48): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n    (49): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (50): LeakyReLU(negative_slope=0.1)\n    (51): Dropout(p=0.5, inplace=False)\n    (52): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (53): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (54): LeakyReLU(negative_slope=0.1)\n    (55): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (56): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (57): LeakyReLU(negative_slope=0.1)\n    (58): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (59): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (60): Dropout(p=0.5, inplace=False)\n    (61): LeakyReLU(negative_slope=0.1)\n    (62): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (63): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (64): LeakyReLU(negative_slope=0.1)\n    (65): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (66): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (67): Dropout(p=0.5, inplace=False)\n    (68): LeakyReLU(negative_slope=0.1)\n  )\n  (fc_layers): Sequential(\n    (0): Flatten(start_dim=1, end_dim=-1)\n    (1): Linear(in_features=50176, out_features=4096, bias=True)\n    (2): LeakyReLU(negative_slope=0.1)\n    (3): Dropout(p=0.5, inplace=False)\n    (4): Linear(in_features=4096, out_features=637, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"class YOLOLoss(nn.Module):\n    def __init__(self, s=7, b=2, c=3, lambda_coord=5e-4, lambda_noobj=0.5,lambda_class=0.1):\n        super().__init__()\n        self.s = s\n        self.b = b\n        self.c = c\n        self.lambda_coord = lambda_coord\n        self.lambda_noobj = lambda_noobj\n        self.lambda_class = lambda_class\n\n    def forward(self, predictions, targets):\n        predictions = predictions.float()\n        targets = targets.float()\n\n        predictions = predictions.reshape(-1, self.s, self.s, self.c + self.b * 5)\n\n        # Split predictions\n        pred_classes = torch.sigmoid(predictions[..., :self.c])\n\n        # Box 1\n        pred_box_1_xy = torch.sigmoid(predictions[..., self.c:self.c + 2])\n        pred_box_1_wh = torch.exp(torch.clamp(predictions[..., self.c + 2:self.c + 4], -100, 4.6))\n        pred_box_1_conf = torch.sigmoid(predictions[..., self.c + 4:self.c + 5])\n        pred_box_1 = torch.cat([pred_box_1_xy, pred_box_1_wh], dim=-1)\n\n        # Box 2\n        pred_box_2_xy = torch.sigmoid(predictions[..., self.c + 5:self.c + 7])\n        pred_box_2_wh = torch.exp(torch.clamp(predictions[..., self.c + 7:self.c + 9], -100, 4.6))\n        pred_box_2_conf = torch.sigmoid(predictions[..., self.c + 9:self.c + 10])\n        pred_box_2 = torch.cat([pred_box_2_xy, pred_box_2_wh], dim=-1)\n\n        \n\n        # Target components\n        target_classes = targets[..., :self.c]\n        target_box_1 = targets[..., self.c:self.c + 4]\n        target_box_2 = targets[..., self.c + 5:self.c + 9]\n        target_box_1_conf = targets[..., self.c + 4:self.c + 5]\n        target_box_2_conf = targets[..., self.c + 9:self.c + 10]\n        \n\n        # Loss components\n        class_loss = torch.sum((target_classes - pred_classes) ** 2) * self.lambda_class\n\n\n        box_1_loss = torch.sum((target_box_1 - pred_box_1) ** 2) * self.lambda_coord\n        if target_box_2.size(-1) > 0:\n            box_2_loss = torch.sum((target_box_2 - pred_box_2) ** 2) * self.lambda_coord\n        else:\n            target_box_2 = torch.zeros_like(pred_box_2)\n            box_2_loss = 0 \n\n\n        obj_loss = torch.sum((target_box_1_conf - pred_box_1_conf) ** 2) * self.lambda_coord\n        noobj_loss = torch.sum((target_box_2_conf - pred_box_2_conf) ** 2) * self.lambda_noobj\n\n        total_loss = class_loss + box_1_loss + box_2_loss + obj_loss + noobj_loss\n        return total_loss\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:47.604218Z","iopub.execute_input":"2024-11-20T05:56:47.604604Z","iopub.status.idle":"2024-11-20T05:56:47.616797Z","shell.execute_reply.started":"2024-11-20T05:56:47.604571Z","shell.execute_reply":"2024-11-20T05:56:47.615730Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom torchvision.ops import box_iou\nfrom torch.nn.functional import mse_loss , binary_cross_entropy_with_logits ,binary_cross_entropy\nimport torch.nn.functional as F","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:47.879318Z","iopub.execute_input":"2024-11-20T05:56:47.879955Z","iopub.status.idle":"2024-11-20T05:56:47.884881Z","shell.execute_reply.started":"2024-11-20T05:56:47.879918Z","shell.execute_reply":"2024-11-20T05:56:47.883797Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"import torch.optim as optim\nimport time\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm  # Import tqdm for progress bar\n\n# Instantiate the YOLOv1 model and YOLOLoss\nmodel = YOLOv1(s=7, b=2, c=3).to(device)\ncriterion = YOLOLoss(s=7, b=2, c=3).to(device)\n\n# Optimizer\noptimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n\n# Set the number of epochs\nepochs = 5\n\n# Set device (GPU or CPU)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Instantiate the dataset and dataloader\ndataset_train = MalariaDataset(\n    \"/kaggle/input/lacuna-malaria-detection-dataset/Train.csv\",\n    \"/kaggle/input/lacuna-malaria-detection-dataset/images\",\n    transform=transform\n)\ntrain_dataloader = DataLoader(dataset_train, batch_size=8, collate_fn=collate_fn)\n\n# Training loop\ndef train():\n    model.train()\n    running_loss = 0.0\n    start_time = time.time()\n\n    for epoch in range(epochs):\n        epoch_loss = 0.0\n        # Wrap the DataLoader with tqdm to show progress\n        with tqdm(train_dataloader, desc=f\"Epoch [{epoch+1}/{epochs}]\", unit=\"batch\") as pbar:\n            for i, (images, targets) in enumerate(pbar):\n                images = images.to(device)\n                targets = targets.to(device)\n\n                # Zero the parameter gradients\n                optimizer.zero_grad()\n\n                # Forward pass\n                predictions = model(images)\n\n                \n\n                # Compute loss\n                loss = criterion(predictions, targets)\n\n                # Backward pass and optimization\n                loss.backward()\n                optimizer.step()\n\n                # Accumulate the loss\n                epoch_loss += loss.item()\n\n                # Update progress bar description with loss\n                pbar.set_postfix(loss=loss.item())\n\n        # Print epoch loss\n        print(f\"Epoch [{epoch+1}/{epochs}], Epoch Loss: {epoch_loss / len(train_dataloader):.4f}\")\n\n        # Calculate elapsed time for each epoch\n        elapsed_time = time.time() - start_time\n        print(f\"Time elapsed for epoch {epoch+1}: {elapsed_time:.2f} seconds\")\n\n    print(\"Training complete!\")\n\n# Run training\ntrain()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:48.418366Z","iopub.execute_input":"2024-11-20T05:56:48.418732Z","iopub.status.idle":"2024-11-20T06:37:40.752633Z","shell.execute_reply.started":"2024-11-20T05:56:48.418701Z","shell.execute_reply":"2024-11-20T06:37:40.751694Z"}},"outputs":[{"name":"stderr","text":"Epoch [1/5]: 100%|██████████| 344/344 [09:18<00:00,  1.62s/batch, loss=0.244]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/5], Epoch Loss: 2.5443\nTime elapsed for epoch 1: 558.23 seconds\n","output_type":"stream"},{"name":"stderr","text":"Epoch [2/5]: 100%|██████████| 344/344 [08:03<00:00,  1.41s/batch, loss=0.122] \n","output_type":"stream"},{"name":"stdout","text":"Epoch [2/5], Epoch Loss: 1.9883\nTime elapsed for epoch 2: 1041.57 seconds\n","output_type":"stream"},{"name":"stderr","text":"Epoch [3/5]: 100%|██████████| 344/344 [08:00<00:00,  1.40s/batch, loss=0.12]  \n","output_type":"stream"},{"name":"stdout","text":"Epoch [3/5], Epoch Loss: 2.4606\nTime elapsed for epoch 3: 1521.77 seconds\n","output_type":"stream"},{"name":"stderr","text":"Epoch [4/5]: 100%|██████████| 344/344 [07:49<00:00,  1.36s/batch, loss=0.119] \n","output_type":"stream"},{"name":"stdout","text":"Epoch [4/5], Epoch Loss: 2.5703\nTime elapsed for epoch 4: 1990.89 seconds\n","output_type":"stream"},{"name":"stderr","text":"Epoch [5/5]: 100%|██████████| 344/344 [07:36<00:00,  1.33s/batch, loss=0.124] ","output_type":"stream"},{"name":"stdout","text":"Epoch [5/5], Epoch Loss: 2.5493\nTime elapsed for epoch 5: 2447.60 seconds\nTraining complete!\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}